<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>VCAA Local Access</title>
    <style>
      :root {
        color-scheme: light;
        font-family: "Segoe UI", -apple-system, system-ui, sans-serif;
        --bg: radial-gradient(circle at top right, #1d4ed8 0%, #0f172a 45%, #020617 100%);
        --card: #ffffff;
        --accent: #2563eb;
        --accent-dark: #1d4ed8;
        --muted: #475569;
        --border: #e2e8f0;
      }

      * {
        box-sizing: border-box;
      }

      body {
        margin: 0;
        min-height: 100vh;
        background: var(--bg);
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 2rem 1rem;
      }

      main {
        width: min(540px, 100%);
      }

      .card {
        background: var(--card);
        border-radius: 28px;
        padding: 2.25rem;
        box-shadow: 0 25px 60px rgba(2, 6, 23, 0.45);
        border: 1px solid rgba(148, 163, 184, 0.4);
        display: flex;
        flex-direction: column;
        gap: 1.25rem;
      }

      header h1 {
        margin: 0.1rem 0 0.3rem;
        font-size: 2rem;
      }

      .eyebrow {
        letter-spacing: 0.2em;
        text-transform: uppercase;
        font-size: 0.75rem;
        color: var(--muted);
      }

      .lead {
        margin: 0;
        color: var(--muted);
        line-height: 1.6;
      }

      label {
        font-size: 0.85rem;
        color: var(--muted);
        display: flex;
        flex-direction: column;
        gap: 0.4rem;
      }

      textarea {
        width: 100%;
        min-height: 270px;
        border-radius: 18px;
        border: 1px solid var(--border);
        padding: 1.1rem;
        resize: vertical;
        font-size: 1.35rem;
        line-height: 1.5;
        font-family: inherit;
        background: #f8fafc;
        transition: border-color 0.2s ease, box-shadow 0.2s ease;
      }

      label input,
      input[type="url"] {
        border-radius: 16px;
        border: 1px solid var(--border);
        padding: 0.85rem 1rem;
        font-size: 1rem;
        font-family: inherit;
        background: #f8fafc;
        transition: border-color 0.2s ease, box-shadow 0.2s ease;
      }

      label input:focus,
      input[type="url"]:focus {
        border-color: var(--accent);
        box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.15);
        outline: none;
      }

      textarea:focus {
        border-color: var(--accent);
        box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.15);
        outline: none;
      }

      .controls {
        display: grid;
        grid-template-columns: 1fr auto;
        gap: 0.75rem;
        align-items: stretch;
      }

      button {
        border: none;
        border-radius: 20px;
        font-weight: 600;
        cursor: pointer;
        transition: transform 0.15s ease, box-shadow 0.15s ease;
      }

      button:active {
        transform: scale(0.98);
      }

      #micButton {
        background: linear-gradient(135deg, #2563eb, #1d4ed8);
        color: white;
        font-size: 1.25rem;
        padding: 0;
        height: 100px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        gap: 0.2rem;
        box-shadow: 0 15px 35px rgba(37, 99, 235, 0.35);
      }

      #micButton span {
        pointer-events: none;
      }

      #runButton {
        background: #f8fafc;
        border: 2px solid var(--border);
        color: var(--muted);
        font-size: 1rem;
        padding: 0 1.5rem;
        min-height: 100px;
      }

      #runButton:hover {
        border-color: var(--accent);
        color: var(--accent-dark);
      }

      #status {
        font-size: 0.9rem;
        color: var(--muted);
        margin-bottom: 0.25rem;
      }

      #output {
        background: #0f172a;
        color: #e2e8f0;
        border-radius: 16px;
        padding: 1rem;
        font-size: 0.95rem;
        min-height: 140px;
        overflow: auto;
        margin: 0;
      }

      @media (max-width: 640px) {
        .card {
          padding: 1.5rem;
        }

        .controls {
          grid-template-columns: 1fr;
        }

        #runButton {
          min-height: 64px;
        }
      }
    </style>
  </head>
  <body>
    <main>
      <section class="card" aria-live="polite">
        <header>
          <p class="eyebrow">VCAA Local Access</p>
          <h1>Voice-Controlled Assistive Agent</h1>
          <p class="lead">
            Large controls let you dictate tasks and trigger actions without precision clicking.
          </p>
        </header>
        <label for="promptInput">Prompt</label>
        <textarea
          id="promptInput"
          placeholder="Show me the cheapest flights from Istanbul to London on January 21, 2026."
        ></textarea>
        <label class="api-label" for="apiBase">
          API base
          <input id="apiBase" type="url" value="http://localhost:8081" />
        </label>
        <div class="controls">
          <button id="micButton" type="button" aria-pressed="false">
            <span aria-hidden="true">üéôÔ∏è</span>
            <span class="mic-text">Tap to speak</span>
          </button>
          <button id="runButton" type="button">Run demo</button>
        </div>
        <div id="status">Ready for your command.</div>
        <pre id="output">Action plan response will display here.</pre>
      </section>
    </main>
    <script>
      const micButton = document.getElementById("micButton");
      const runButton = document.getElementById("runButton");
      const status = document.getElementById("status");
      const output = document.getElementById("output");
      const promptInput = document.getElementById("promptInput");
      const apiBaseInput = document.getElementById("apiBase");

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition || null;
      let recognition = null;
      let isListening = false;
      let microphonePermissionGranted = false;

      const isExtensionContext =
        typeof globalThis.chrome?.runtime?.sendMessage === "function";

      const uuid = () =>
        window.crypto?.randomUUID?.() ?? `${Date.now()}-${Math.random().toString(16).slice(2)}`;

      const normalizeApiBase = (value) => {
        if (!value) {
          return "http://localhost:8081";
        }
        const trimmed = value.trim();
        if (/^https?:\/\//i.test(trimmed)) {
          return trimmed.replace(/\/$/, "");
        }
        return `http://${trimmed.replace(/\/$/, "")}`;
      };

      const logStatus = (msg) => {
        status.textContent = msg;
      };

      const formatResponseOutput = (resp) => {
        if (!resp) {
          return "No response received.";
        }
        if (resp.status === "error") {
          return resp.error || "An unknown error occurred.";
        }
        if (resp.status === "needs_clarification") {
          return "Clarification required.";
        }
        const lines = [];
        if (resp.actionPlan) {
          lines.push(`Action plan: ${resp.actionPlan.action} ‚Üí ${resp.actionPlan.target}`);
        }
        if (resp.executionPlan?.steps?.length) {
          lines.push("Execution steps:");
          resp.executionPlan.steps.forEach((step) => {
            const valuePart = step.value ? ` = "${step.value}"` : "";
            lines.push(
              `  ‚Ä¢ ${step.action_type} ${step.element_id || "(unknown element)"}${valuePart}`
            );
          });
        }
        if (resp.execResult) {
          lines.push(`Execution result: ${resp.execResult.status || "unknown status"}`);
        }
        return lines.join("\n") || "Completed with no additional details.";
      };

      const updateMicButtonLabel = (override) => {
        if (!SpeechRecognition) {
          micButton.textContent = "üéôÔ∏è Speech unavailable";
          micButton.disabled = true;
          return;
        }
        const label = micButton.querySelector(".mic-text");
        if (override) {
          label.textContent = override;
          return;
        }
        label.textContent = isListening ? "Listening‚Ä¶ speak clearly" : "Tap to speak";
      };

      const ensureRecognition = () => {
        if (!SpeechRecognition) {
          return null;
        }
        if (recognition) {
          return recognition;
        }
        recognition = new SpeechRecognition();
        recognition.lang = "en-US";
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;
        recognition.continuous = false;

        recognition.onresult = (event) => {
          const transcript = event.results?.[0]?.[0]?.transcript?.trim();
          if (transcript) {
            promptInput.value = transcript;
            output.textContent = `Heard: ${transcript}`;
            logStatus("Prompt updated from speech.");
            submitPrompt(transcript, true);
          }
        };

        recognition.onend = () => {
          isListening = false;
          updateMicButtonLabel();
          logStatus("Ready for your command.");
        };

        recognition.onerror = (event) => {
          isListening = false;
          updateMicButtonLabel();
          output.textContent = `Speech recognition error: ${event.error || "unknown"}`;
          logStatus("Speech recognition failed.");
        };

        return recognition;
      };

      const requestMicrophoneAccess = async () => {
        if (!navigator.mediaDevices?.getUserMedia) {
          output.textContent = "Microphone APIs are not supported in this browser.";
          return false;
        }
        if (microphonePermissionGranted) {
          return true;
        }
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          stream.getTracks().forEach((track) => track.stop());
          microphonePermissionGranted = true;
          return true;
        } catch (err) {
          output.textContent = `Microphone access denied: ${err.message || err}`;
          return false;
        }
      };

      const toggleListening = async () => {
        if (!SpeechRecognition) {
          output.textContent = "Speech recognition is not available.";
          return;
        }
        const recognizer = ensureRecognition();
        if (!recognizer) {
          output.textContent = "Unable to initialize speech recognition.";
          return;
        }
        if (isListening) {
          recognizer.stop();
          isListening = false;
          updateMicButtonLabel();
          return;
        }
        const granted = await requestMicrophoneAccess();
        if (!granted) {
          updateMicButtonLabel();
          return;
        }
        try {
          isListening = true;
          updateMicButtonLabel();
          logStatus("Microphone active. Speak now.");
          output.textContent = "Listening for speech‚Ä¶";
          recognizer.start();
        } catch (err) {
          isListening = false;
          updateMicButtonLabel();
          output.textContent = `Failed to start speech recognition: ${err?.message || err}`;
          logStatus("Ready for your command.");
        }
      };

      micButton.addEventListener("click", toggleListening);
      updateMicButtonLabel();

      const requestActionPlan = async (prompt, apiBase) => {
        const base = normalizeApiBase(apiBase);
        const endpoint = `${base}/api/interpreter/actionplan`;
        const body = {
          schema_version: "stt_v1",
          id: uuid(),
          trace_id: uuid(),
          transcript: prompt,
          metadata: { source: "local-access" },
        };
        const resp = await fetch(endpoint, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(body),
        });
        if (!resp.ok) {
          throw new Error(`Interpreter returned ${resp.status}: ${resp.statusText}`);
        }
        return resp.json();
      };

      const callExtensionRunDemo = async (transcript) =>
        new Promise((resolve, reject) => {
          if (!isExtensionContext) {
            reject(new Error("Extension runtime unavailable"));
            return;
          }
          chrome.runtime.sendMessage(
            { type: "vcaa-run-demo", transcript },
            (resp) => {
              if (chrome.runtime.lastError) {
                reject(new Error(chrome.runtime.lastError.message));
                return;
              }
              resolve(resp);
            }
          );
        });

      const submitPrompt = async (prompt, autoTriggered = false) => {
        const trimmed = prompt.trim();
        if (!trimmed) {
          logStatus("Please enter or dictate a prompt first.");
          output.textContent = "No prompt provided.";
          return;
        }
        logStatus("Sending prompt to VCAA agents‚Ä¶");
        output.textContent = `Prompt queued: "${trimmed}"`;
        runButton.disabled = true;
        try {
          let response;
          if (isExtensionContext) {
            response = await callExtensionRunDemo(trimmed);
            output.textContent = formatResponseOutput(response);
          } else {
            const actionPlan = await requestActionPlan(trimmed, apiBaseInput.value);
            output.textContent = JSON.stringify(actionPlan, null, 2);
            response = actionPlan;
          }
          const confidence =
            typeof response?.confidence === "number" ? response.confidence.toFixed(2) : "n/a";
          logStatus(
            isExtensionContext
              ? `Interpreter ready (confidence ${confidence}).`
              : "Interpreter request completed."
          );
        } catch (err) {
          logStatus("Unable to reach the local bridge.");
          output.textContent = `Error: ${err.message}`;
        } finally {
          runButton.disabled = false;
        }
        if (autoTriggered) {
          micButton.focus();
        }
      };

      runButton.addEventListener("click", () => submitPrompt(promptInput.value));

      const loadConfig = () => {
        if (isExtensionContext) {
          chrome.storage.sync.get(["vcaaApiBase"], (result) => {
            if (result.vcaaApiBase) {
              apiBaseInput.value = result.vcaaApiBase;
            }
          });
        } else {
          apiBaseInput.value = "http://localhost:8081";
        }
      };

      loadConfig();

      if (isExtensionContext) {
        apiBaseInput.addEventListener("change", () => {
          chrome.runtime.sendMessage(
            { type: "vcaa-set-api", apiBase: apiBaseInput.value },
            () => {}
          );
        });
      }
    </script>
  </body>
</html>
